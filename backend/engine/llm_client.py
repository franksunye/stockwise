"""
LLM å®¢æˆ·ç«¯æ¨¡å—
å°è£…æœ¬åœ° LLM ä»£ç†æœåŠ¡çš„è°ƒç”¨é€»è¾‘
"""

import json
import requests
from typing import Optional, Dict, Any
import time
from config import LLM_CONFIG


class LLMClient:
    """æœ¬åœ° LLM ä»£ç†å®¢æˆ·ç«¯"""
    
    def __init__(
        self,
        base_url: str = None,
        api_key: str = None,
        model: str = None,
        timeout: int = 120
    ):
        """
        åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
        
        Args:
            base_url: API åŸºç¡€åœ°å€ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®
            api_key: API å¯†é’¥ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®
            model: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.base_url = base_url or LLM_CONFIG.get("base_url", "http://127.0.0.1:8045/v1")
        self.api_key = api_key or LLM_CONFIG.get("api_key", "")
        self.model = model or LLM_CONFIG.get("model", "gpt-3.5-turbo")
        self.timeout = timeout
        
    def is_available(self) -> bool:
        """æ£€æŸ¥ LLM æœåŠ¡æ˜¯å¦å¯ç”¨"""
        try:
            response = requests.get(
                f"{self.base_url}/models",
                timeout=5,
                headers={"Authorization": f"Bearer {self.api_key}"}
            )
            return response.status_code == 200
        except:
            return False
    
    def chat(
        self,
        messages: list,
        model: str = None,
        temperature: float = 0.7,
        max_tokens: int = 2000
    ) -> Optional[str]:
        """
        å‘é€èŠå¤©è¯·æ±‚
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ [{"role": "user/system/assistant", "content": "..."}]
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¯è¦†ç›–é»˜è®¤ï¼‰
            temperature: ç”Ÿæˆæ¸©åº¦
            max_tokens: æœ€å¤§è¾“å‡º token æ•°
            
        Returns:
            LLM è¿”å›çš„æ–‡æœ¬å†…å®¹ï¼Œå¤±è´¥è¿”å› None
        """
        payload = {
            "model": model or self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": 4000, # ç¡®ä¿æœ‰è¶³å¤Ÿçš„é•¿åº¦ç”Ÿæˆå®Œæ•´çš„ JSON
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        try:
            start_time = time.time()
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=self.timeout
            )
            elapsed = time.time() - start_time
            
            if response.status_code == 200:
                data = response.json()
                if data.get('choices'):
                    content = data['choices'][0].get('message', {}).get('content')
                    print(f"   ğŸ¤– LLM å“åº”æˆåŠŸ ({elapsed:.1f}s)")
                    return content
                else:
                    print(f"   âš ï¸ LLM å“åº”æ ¼å¼å¼‚å¸¸: {data}")
                    return None
            else:
                print(f"   âŒ LLM è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            print(f"   âŒ LLM è¯·æ±‚è¶…æ—¶ ({self.timeout}s)")
            return None
        except requests.exceptions.ConnectionError:
            print(f"   âŒ æ— æ³•è¿æ¥ LLM æœåŠ¡: {self.base_url}")
            return None
        except Exception as e:
            print(f"   âŒ LLM è¯·æ±‚å¼‚å¸¸: {e}")
            return None
    
    def generate_stock_prediction(
        self,
        system_prompt: str,
        user_prompt: str,
        retries: int = 2
    ) -> Optional[Dict[str, Any]]:
        """
        ç”Ÿæˆè‚¡ç¥¨é¢„æµ‹ï¼ˆå¸¦ JSON è§£æå’Œé‡è¯•ï¼‰
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå®šä¹‰è¾“å‡ºæ ¼å¼ï¼‰
            user_prompt: ç”¨æˆ·è¾“å…¥ï¼ˆè‚¡ç¥¨æ•°æ®ï¼‰
            retries: é‡è¯•æ¬¡æ•°
            
        Returns:
            è§£æåçš„é¢„æµ‹ç»“æœ dictï¼Œå¤±è´¥è¿”å› None
        """
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        for attempt in range(retries + 1):
            if attempt > 0:
                print(f"   ğŸ”„ é‡è¯• {attempt}/{retries}...")
                
            content = self.chat(messages, temperature=0.5)
            
            if content:
                # å°è¯•è§£æ JSON
                result = self._parse_json_response(content)
                if result:
                    return result
                else:
                    print(f"   âš ï¸ JSON è§£æå¤±è´¥ï¼ŒåŸå§‹å†…å®¹:\n{content}")
            
        return None
    
    def _parse_json_response(self, content: str) -> Optional[Dict[str, Any]]:
        """
        è§£æ LLM è¿”å›çš„ JSON å†…å®¹ï¼ˆå¤„ç† markdown ä»£ç å—ã€åµŒå¥—åŠä¸å®Œæ•´å†…å®¹ï¼‰
        """
        if not content:
            return None
            
        # æ¸…ç†å¸¸è§çš„å¹²æ‰°å­—ç¬¦
        content = content.strip()
        
        # 1. å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            pass
            
        # 2. å°è¯•æå–æ‰€æœ‰ ```json ... ``` å—å¹¶è§£æï¼ˆä¼˜å…ˆä»åå¾€å‰æ‰¾ï¼‰
        import re
        json_blocks = re.findall(r'```json\s*(.*?)\s*```', content, re.DOTALL)
        if not json_blocks:
            # å°è¯•å¤„ç†åªæœ‰å¼€å§‹æ²¡æœ‰ç»“æŸçš„ä»£ç å—ï¼ˆæˆªæ–­æƒ…å†µï¼‰ï¼ŒåŒæ ·ä¼˜å…ˆåæ–¹çš„
            json_blocks = re.findall(r'```json\s*(.*)', content, re.DOTALL)
            
        if json_blocks:
            # ä»åå¾€å‰å°è¯•è§£æï¼Œå› ä¸ºæ¨¡å‹å¹»è§‰å¾€å¾€æ˜¯åœ¨åé¢é‡æ–°è¾“å‡ºäº†æ­£ç¡®çš„å®Œæ•´å—
            for block in reversed(json_blocks):
                try:
                    # å†æ¬¡æ¸…ç†å—å†…å¯èƒ½å­˜åœ¨çš„åµŒå¥—å¹»è§‰ï¼ˆæˆªæ–­åˆ°ä¸‹ä¸€ä¸ª ``` ä¹‹å‰ï¼‰
                    clean_block = block.split('```')[0].strip()
                    return json.loads(clean_block)
                except json.JSONDecodeError as e:
                    # å°è¯•ä¿®å¤ç”±äºæˆªæ–­å¯¼è‡´çš„ JSON ä¸å®Œæ•´
                    if "Expecting ',' delimiter" in str(e) or "Expecting value" in str(e) or "Unterminated string" in str(e):
                        try:
                            # å°è¯•åœ¨æœ«å°¾è¡¥å…¨å°é—­å­—ç¬¦ï¼ˆä»…å½“ç¡®å®æœ‰å†…å®¹æ—¶ï¼‰
                            if len(clean_block) > 50:
                                for suffix in [" }", '" }', '" } ] }', ' } ] }']:
                                    try:
                                        return json.loads(clean_block + suffix)
                                    except:
                                        continue
                        except:
                            pass
                    continue
                
        # 3. å°è¯•æå–ç®€å•çš„ ``` ... ``` å—
        code_blocks = re.findall(r'```\s*(.*?)\s*```', content, re.DOTALL)
        for block in code_blocks:
            try:
                # å†æ¬¡æ£€æŸ¥æ˜¯å¦å«æœ‰åµŒå¥—çš„ json æ ‡è¯†
                clean_block = re.sub(r'^json\s*', '', block.strip())
                return json.loads(clean_block)
            except json.JSONDecodeError:
                continue
                
        # 4. å°è¯•å¯»æ‰¾ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
        try:
            start = content.find('{')
            end = content.rfind('}') + 1
            if start >= 0 and end > start:
                json_str = content[start:end]
                # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ä¸­é—´ markdown æ ‡è®°
                json_str = re.sub(r'```json|```', '', json_str)
                return json.loads(json_str)
        except:
            pass
            
        return None


# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
_client: Optional[LLMClient] = None


def get_llm_client() -> LLMClient:
    """è·å–å…¨å±€ LLM å®¢æˆ·ç«¯å®ä¾‹"""
    global _client
    if _client is None:
        _client = LLMClient()
    return _client


def test_llm_connection() -> bool:
    """æµ‹è¯• LLM è¿æ¥"""
    client = get_llm_client()
    if not client.is_available():
        print("âŒ LLM æœåŠ¡ä¸å¯ç”¨")
        return False
    
    print("âœ… LLM æœåŠ¡è¿æ¥æˆåŠŸ")
    response = client.chat([{"role": "user", "content": "å›å¤'OK'"}])
    if response:
        print(f"   æµ‹è¯•å“åº”: {response[:50]}...")
        return True
    return False


if __name__ == "__main__":
    test_llm_connection()
