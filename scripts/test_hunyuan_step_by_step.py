
import sys
import os
import json
import time

# Add project root AND backend to path to allow both absolute and relative-style imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

try:
    from backend.engine.llm_client import LLMClient
except ImportError:
    import traceback
    traceback.print_exc()
    print(f"Current sys.path: {sys.path}")
    sys.exit(1)

def main():
    print("ğŸš€ Starting Structured Prompting Test for Hunyuan Lite...")
    
    # Initialize Client directly with Hunyuan provider
    # Ensure HUNYUAN_API_KEY is in env or .env
    client = LLMClient(provider="hunyuan")
    
    # Note: Skipping is_available() check as Hunyuan API does not support the /models endpoint.
    # The API Key will be validated on the first actual request.
    print(f"âœ… Initializing Hunyuan Client ({client.model})")

    # --- Conversation History ---
    messages = []
    
    # --- System Prompt ---
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„é‡‘èåˆ†æåŠ©ç†ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¾…åŠ©äººç±»åˆ†æå¸ˆå®Œæˆè‚¡ç¥¨èµ°åŠ¿é¢„æµ‹ã€‚
ä¸ºäº†é˜²æ­¢å¹»è§‰å’Œé€»è¾‘æ··ä¹±ï¼Œæˆ‘ä»¬å°†åˆ†4æ­¥è¿›è¡Œåˆ†æã€‚
è¯·ä¸¥æ ¼éµå®ˆæ¯ä¸€æ­¥çš„æŒ‡ä»¤ï¼Œä¸è¦æŠ¢ç­”ï¼Œä¸è¦ç¼–é€ æ•°æ®ã€‚
æ•°å€¼å¿…é¡»ç²¾å‡†åŒ¹é…ï¼Œä¸å¾—å››èˆäº”å…¥ã€‚"""
    
    messages.append({"role": "system", "content": system_prompt})

    # --- Step 1: Data Anchoring (Full Parity) ---
    step1_prompt = """### æ­¥éª¤1ï¼šåŸºç¡€é”šå®šæ•°æ®æŠ•å–‚
è¯·ç²¾å‡†è®°å½•ä»¥ä¸‹è‚¡ç¥¨åŸºç¡€æ•°æ®åŠè¿‘10æ—¥è¡Œæƒ…ï¼š

## 1. åŸºç¡€ä¿¡æ¯
- **è…¾è®¯æ§è‚¡** (00700.HK)
- æ—¥æœŸ: 2026-01-06
- **è¡Œä¸š**: è½¯ä»¶æœåŠ¡
- **å…¬å¸ç®€ä»‹**: è…¾è®¯æ§è‚¡æœ‰é™å…¬å¸æ˜¯ä¸€å®¶ä¸–ç•Œé¢†å…ˆçš„äº’è”ç½‘ç§‘æŠ€å…¬å¸ï¼Œæˆç«‹äº1998å¹´ï¼Œæ€»éƒ¨ä½äºä¸­å›½æ·±åœ³ã€‚

## 2. ä»·æ ¼è¡Œä¸º (Price Action) - è¿‘10æ—¥è¡Œæƒ…
| æ—¥æœŸ       | å¼€ç›˜  | æœ€é«˜  | æœ€ä½  | æ”¶ç›˜  | æ¶¨è·Œå¹…   | æˆäº¤é‡   |
| ---------- | ----- | ----- | ----- | ----- | -------- | -------- |
| 2026-01-06 | 627.0 | 638.5 | 626.0 | 632.5 | +1.28% ğŸ“ˆ | 24168431 |
| 2026-01-05 | 624.0 | 628.0 | 615.5 | 624.5 | +0.24% ğŸ“ˆ | 19947025 |
| 2026-01-02 | 600.5 | 624.5 | 600.5 | 623.0 | +4.01% ğŸ“ˆ | 16200058 |
| 2025-12-31 | 597.5 | 602.5 | 596.0 | 599.0 | -0.17% ğŸ“‰ | 10838209 |
| 2025-12-30 | 598.5 | 601.0 | 594.0 | 600.0 | +0.59% ğŸ“ˆ | 13582535 |
| 2025-12-29 | 606.0 | 611.0 | 596.0 | 596.5 | -1.08% ğŸ“‰ | 18502650 |
| 2025-12-24 | 598.0 | 604.5 | 598.0 | 603.0 | +0.17% ğŸ“ˆ | 7324553  |
| 2025-12-23 | 613.5 | 614.5 | 601.5 | 602.0 | -2.03% ğŸ“‰ | 15623392 |
| 2025-12-22 | 620.0 | 621.5 | 610.0 | 614.5 | +0.08% ğŸ“ˆ | 13868060 |
| 2025-12-19 | 610.0 | 617.5 | 607.0 | 614.0 | +1.49% ğŸ“ˆ | 17765762 |

ä»»åŠ¡ï¼šç¡®è®¤æ•°æ®æ— è¯¯åï¼Œè¾“å‡ºã€Œæ•°æ®å·²é”šå®šï¼šè…¾è®¯æ§è‚¡ (00700.HK) @ 632.5ã€ï¼Œæ— éœ€é¢å¤–åˆ†æã€‚"""

    print("\nğŸ”¹ Step 1: Sending Anchor Data...")
    content, _ = client.chat(messages + [{"role": "user", "content": step1_prompt}])
    print(f"ğŸ¤– AI Response:\n{content}")
    
    if content:
        messages.append({"role": "user", "content": step1_prompt})
        messages.append({"role": "assistant", "content": content})
    else:
        print("âŒ Step 1 failed.")
        return

    # --- Step 2: Indicators ---
    step2_prompt = """### æ­¥éª¤2ï¼šå…³é”®æŒ‡æ ‡ä¸å‘¨æœŸæå€¼
åŸºäºå·²é”šå®šçš„æ•°æ®ï¼Œè¡¥å……ä»¥ä¸‹æ ¸å¿ƒæŒ‡æ ‡ï¼š

å‘¨æœŸæå€¼ï¼š
- è¿‘10æ—¥æœ€é«˜ä»·ï¼š638.5
- è¿‘10æ—¥æœ€ä½ä»·ï¼š594.0

æ ¸å¿ƒæŒ‡æ ‡ (æ—¥çº¿)ï¼š
- MA20ï¼š607.83 (å¤šå¤´æ’åˆ—)
- MA60ï¼š0.0 (æ— æ•°æ®)
- RSI (14)ï¼š62.0 (è¿è¡Œç¨³å¥)
- MACDï¼šæ­»å‰/ç©ºå¤´
- å¸ƒæ—å¸¦ï¼šä¸Šè½¨ 627.13ï¼Œä¸‹è½¨ 588.52ï¼Œæ”¶ç›˜ä»·(632.5)å·²çªç ´ä¸Šè½¨

ä»»åŠ¡ï¼š
1. åˆ¤æ–­å‡çº¿è¶‹åŠ¿ï¼ˆå¤šå¤´/ç©ºå¤´/çº ç¼ ï¼‰
2. åˆ¤æ–­RSIä½ç½®ï¼ˆè¶…ä¹°/è¶…å–/ä¸­æ€§ï¼‰
3. åˆ†æå½“å‰ä»·æ ¼ç›¸å¯¹å¸ƒæ—å¸¦çš„ä½ç½®é£é™©
4. è¾“å‡ºç®€çŸ­åˆ†æï¼Œæš‚ä¸ç»™å‡ºä¹°å–ç»“è®ºã€‚"""

    print("\nğŸ”¹ Step 2: Sending Indicators...")
    content, _ = client.chat(messages + [{"role": "user", "content": step2_prompt}])
    print(f"ğŸ¤– AI Response:\n{content}")

    if content:
        messages.append({"role": "user", "content": step2_prompt})
        messages.append({"role": "assistant", "content": content})
    else:
        print("âŒ Step 2 failed.")
        return

    # --- Step 3: Multi-period Context & Verification ---
    step3_prompt = """### æ­¥éª¤3ï¼šå‘¨æœŸèƒŒæ™¯ä¸è¾…åŠ©éªŒè¯
è¯·ç»“åˆä»¥ä¸‹å¤šå‘¨æœŸæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æï¼š

## 1. å‘¨æœŸèƒŒæ™¯ (Context)
### å‘¨çº¿é€è§† (æœ€è¿‘8å‘¨)
| å‘¨æœ«æ—¥æœŸ   | æ”¶ç›˜  | æ¶¨è·Œå¹…   | MA20        | RSI      |
| ---------- | ----- | -------- | ----------- | -------- |
| 2026-01-06 | 632.5 | +1.52% ğŸ“ˆ | MA20:626.33 | RSI:59.7 |
| 2025-12-31 | 599.0 | -2.04% ğŸ“‰ | MA20:623.15 | RSI:52.8 |
| ... (å…¶ä½™å‘¨çº¿è§è¡Œæƒ…è¡¨)

### æœˆçº¿é€è§† (æœ€è¿‘3ä¸ªæœˆ)
| æœˆæœ«æ—¥æœŸ   | æ”¶ç›˜  | æ¶¨è·Œå¹…   |
| ---------- | ----- | -------- |
| 2026-01-06 | 632.5 | +5.59% ğŸ“ˆ |
| 2025-12-31 | 599.0 | -2.04% ğŸ“‰ |

- **å¹´åº¦åŒºé—´(è¿‘12ä¸ªæœˆ)**: 414.5 ~ 683.0
- **é•¿æœŸè¶‹åŠ¿**: ç‰›å¸‚ (å½“å‰ä»· vs 20æœˆçº¿)

## 2. AI å†å²é¢„æµ‹å›é¡¾
| é¢„æµ‹æ—¥æœŸ   | ä¿¡å· | ç½®ä¿¡åº¦ | åˆ¤æ–­ | ç»“æœ |
| ---------- | ---- | ------ | ---- | ---- |
| 2025-12-29 | è§‚æœ› | 60%    | çŸ­æœŸæ‰¿å‹ | âœ… |

ä»»åŠ¡ï¼š
1. åˆ†æ "æ—¥çº¿MACDæ­»å‰" åœ¨ "å‘¨çº¿/æœˆçº¿å¤šå¤´" èƒŒæ™¯ä¸‹çš„æ€§è´¨ï¼ˆæ˜¯åè½¬è¿˜æ˜¯å›è¸©ï¼Ÿï¼‰ã€‚
2. åˆ†æå½“å‰ä»· (632.5) åœ¨ "å¹´åº¦åŒºé—´ (414.5~683.0)" ä¸­çš„ä½ç½®æ„Ÿã€‚
3. æŒ‡å‡ºå¤šå‘¨æœŸå…±æŒ¯ç‚¹æˆ–çŸ›ç›¾ç‚¹ã€‚"""

    print("\nğŸ”¹ Step 3: Sending Auxiliary Data...")
    content, _ = client.chat(messages + [{"role": "user", "content": step3_prompt}])
    print(f"ğŸ¤– AI Response:\n{content}")

    if content:
        messages.append({"role": "user", "content": step3_prompt})
        messages.append({"role": "assistant", "content": content})
    else:
        print("âŒ Step 3 failed.")
        return

    # --- Step 4: Final Conclusion (JSON) ---
    step4_prompt = """### æ­¥éª¤4ï¼šæœ€ç»ˆç»“è®ºæ¨å¯¼
æ•´åˆä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆæœ€ç»ˆæ“ä½œå»ºè®® JSONã€‚

é€»è¾‘è¦æ±‚ï¼š
1. ä»·æ ¼çªç ´å¸ƒæ—ä¸Šè½¨(627.13)ä¸”RSI(62.0)å°šæœªæç«¯è¶…ä¹°ï¼Œè¶‹åŠ¿åå¼ºã€‚
2. ä½†MACDæ­»å‰æç¤ºåŠ¨èƒ½å¯èƒ½å‡å¼±ï¼Œéœ€è­¦æƒ•å›è°ƒã€‚
3. ç»¼åˆåˆ¤æ–­ï¼šè™½ç„¶çªç ´äº†ä¸Šè½¨ï¼Œä½†MACDæ­»å‰æ˜¯é‡å¤§çš„èƒŒç¦»ä¿¡å·ã€‚è¯·åƒä¸€ä¸ªæå…¶ä¿å®ˆçš„äº¤æ˜“å‘˜ä¸€æ ·æ€è€ƒï¼š
   - åªè¦æœ‰èƒŒç¦»ï¼Œå°±é»˜è®¤æœ‰é£é™©ã€‚
   - å®æ„¿é”™è¿‡ï¼Œç»ä¸åšé”™ã€‚
   - é™¤éåç»­è¿™3ä¸ªæ¡ä»¶åŒæ—¶æ»¡è¶³ï¼ˆé‡èƒ½ç»§ç»­æ”¾å¤§ + MACDé‡‘å‰ + ç«™ç¨³632.5ï¼‰ï¼Œå¦åˆ™ç°åœ¨å°±æ˜¯"è§‚æœ›"ã€‚
4. å®ç¼ºå‹¿æ»¥ï¼šå¦‚æœæ²¡æœ‰80%æŠŠæ¡ï¼Œé»˜è®¤ "Side" (è§‚æœ›)ã€‚ä¸è¦è¢«çŸ­æœŸæ¶¨å¹…è¯±æƒ‘ã€‚

å¿…é¡»è¾“å‡ºçº¯ JSON æ ¼å¼ï¼Œä¸¥æ ¼éµå®ˆä»¥ä¸‹ Schemaï¼š
{
  "signal": "Long" | "Short" | "Side",
  "confidence": 0.0 - 1.0 (è§‚æœ›å»ºè®® 0.6-0.75),
  "summary": "ä¸€å¥è¯æ€»ç»“",
  "reasoning_trace": [
    { "step": "trend", "data": "å‡çº¿ç›¸å…³æè¿°", "conclusion": "è¶‹åŠ¿ç»“è®º" },
    { "step": "momentum", "data": "RSI/MACDç›¸å…³", "conclusion": "åŠ¨èƒ½ç»“è®º" },
    { "step": "level", "data": "å¸ƒæ—å¸¦/å‹åŠ›ä½ç›¸å…³", "conclusion": "ä½ç½®ç»“è®º" },
    { "step": "decision", "data": "ç»¼åˆåˆ¤æ–­", "conclusion": "æœ€ç»ˆç»“è®º" }
  ],
  "news_analysis": ["æ–°é—»1", "æ–°é—»2"] (è‹¥æ— æ–°é—»åˆ™å¡« ["æ— å®æ—¶æ–°é—»è¾“å…¥ï¼Œä»…åŸºäºæŠ€æœ¯é¢åˆ†æ"]),
  "tactics": {
    "holding": [{ "priority": "P1", "action": "åŠ¨ä½œ", "trigger": "è§¦å‘æ¡ä»¶", "reason": "ç†ç”±" }],
    "empty": [{ "priority": "P1", "action": "åŠ¨ä½œ", "trigger": "è§¦å‘æ¡ä»¶", "reason": "ç†ç”±" }],
    "general": [{ "priority": "P2", "action": "åŠ¨ä½œ", "trigger": "è§¦å‘æ¡ä»¶", "reason": "ç†ç”±" }]
  },
  "key_levels": { 
    "support": <ä½¿ç”¨å¸ƒæ—ä¸‹è½¨588.52æˆ–MA20(607.83)ä½œä¸ºå‚è€ƒ>,
    "resistance": <ä½¿ç”¨è¿‘10æ—¥æœ€é«˜ä»·638.5æˆ–å¸ƒæ—ä¸Šè½¨627.13ä½œä¸ºå‚è€ƒ>,
    "stop_loss": <é€šå¸¸è®¾ç½®åœ¨æ”¯æ’‘ä½ä¸‹æ–¹çº¦3%>
  },
  "conflict_resolution": "è§£é‡Šæœ¬æ¬¡åˆ†æä¸­çš„ä¸»è¦çŸ›ç›¾ç‚¹å¦‚ä½•æƒè¡¡",
  "tomorrow_focus": "æ˜æ—¥é‡ç‚¹å…³æ³¨çš„ä»·æ ¼ä½æˆ–äº‹ä»¶"
}

**IMPORTANT**: 
1. `reasoning_trace` ä¸­çš„ `step` å¿…é¡»æ˜¯è‹±æ–‡: trend, momentum, level, decision.
2. å¿…é¡»åŒ…å« `news_analysis`, `conflict_resolution`, `tomorrow_focus` å­—æ®µ.
3. **ç¦æ­¢è¾“å‡ºä»»ä½•æ•°å­¦å…¬å¼**ã€‚æ‰€æœ‰æ•°å­—å¿…é¡»æ˜¯è®¡ç®—åçš„ç»“æœã€‚ä¾‹å¦‚ï¼š
   - âŒ é”™è¯¯: "stop_loss": 632.5 * 0.97
   - âœ… æ­£ç¡®: "stop_loss": 613.53"""

    print("\nğŸ”¹ Step 4: Requesting Conclusion...")
    content, _ = client.chat(messages + [{"role": "user", "content": step4_prompt}])
    print(f"ğŸ¤– AI Response:\n{content}")
    
    # Validation
    if content:
        try:
            # Try basic cleanup
            clean_content = content.replace("```json", "").replace("```", "").strip()
            data = json.loads(clean_content)
            print("\nâœ… Valid JSON received!")
            print(json.dumps(data, indent=2, ensure_ascii=False))
        except json.JSONDecodeError:
            print("\nâŒ Failed to parse JSON response.")
            print(content)

if __name__ == "__main__":
    main()
