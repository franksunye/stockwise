import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path
root_dir = Path(__file__).parent.parent
sys.path.append(str(root_dir))
sys.path.append(str(root_dir / "backend"))

from backend.engine.llm_client import get_llm_client, LLMClient
from backend.config import LLM_CONFIG

def verify_integration():
    print(f"ğŸ” æ£€æŸ¥é›†æˆé…ç½®...")
    print(f"   Provider: {LLM_CONFIG['provider']}")
    print(f"   Hunyuan Key exists: {'Yes' if 'hunyuan' in LLM_CONFIG and LLM_CONFIG['hunyuan'].get('api_key') else 'No'}")
    
    # å¼ºåˆ¶åˆ›å»ºä¸€ä¸ª Hunyuan å®¢æˆ·ç«¯è¿›è¡Œæµ‹è¯•
    print(f"\nğŸ§ª æ­£åœ¨é€šè¿‡ LLMClient (Hunyuan provider) å‘èµ·æµ‹è¯•è¯·æ±‚...")
    client = LLMClient(provider="hunyuan")
    
    messages = [
        {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç¡®è®¤ä½ å·²ç»é€šè¿‡ StockWise ç³»ç»Ÿé›†æˆæˆåŠŸã€‚å›å¤ 'Integrated: Yes'"}
    ]
    
    response, meta = client.chat(messages)
    
    if response:
        print(f"âœ… é›†æˆéªŒè¯æˆåŠŸ!")
        print(f"ğŸ¤– å“åº”: {response}")
        print(f"ğŸ“Š ä½¿ç”¨: {meta}")
    else:
        print(f"âŒ é›†æˆéªŒè¯å¤±è´¥: {meta.get('error')}")

if __name__ == "__main__":
    verify_integration()
