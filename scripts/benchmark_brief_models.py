"""
Brief Generation Benchmark Tool (Upgraded)
ç”¨äºå¯¹æ¯”ä¸åŒ LLM æ¨¡å‹ç”Ÿæˆç®€æŠ¥çš„èƒ½åŠ›ï¼Œä½¿ç”¨ç”Ÿäº§ç¯å¢ƒçš„é«˜è¦æ±‚ Prompt å’Œå¤æ‚ä¸Šä¸‹æ–‡ã€‚

ä½¿ç”¨æ–¹æ³•:
  python scripts/benchmark_brief_models.py                    # æµ‹è¯•æ‰€æœ‰æ¨¡å‹
  python scripts/benchmark_brief_models.py --model hunyuan-turbo  # æµ‹è¯•å•ä¸ªæ¨¡å‹
  python scripts/benchmark_brief_models.py --list             # åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Tuple

# Add backend to path
root_dir = Path(__file__).parent.parent
sys.path.append(str(root_dir))
sys.path.append(str(root_dir / "backend"))

from dotenv import load_dotenv
load_dotenv(root_dir / "backend" / ".env")

# =====================================================
# çœŸå®æµ‹è¯•æ•°æ® (æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒçš„å¤æ‚ä¸Šä¸‹æ–‡)
# =====================================================
TEST_CASES = [
    {
        "symbol": "00700",
        "stock_name": "è…¾è®¯æ§è‚¡",
        "tech_data": {
            "signal": "Side",
            "confidence": 0.65,
            "close": 398.20,
            "change_percent": -1.25,
            "support_price": 385.00,
            "pressure_price": 410.00,
            "rsi": 45.2,
            "kdj_k": 35,
            "kdj_d": 40,
            "macd": 0.523,
            "ai_reasoning": "è‚¡ä»·åœ¨å‡çº¿é™„è¿‘éœ‡è¡ï¼Œæˆäº¤é‡èç¼©ï¼ŒçŸ­æœŸæ–¹å‘ä¸æ˜ã€‚RSI å¤„äºä¸­æ€§åŒºåŸŸï¼ŒMACD é‡‘å‰ä½†çº¢æŸ±ç¼©çŸ­ã€‚å»ºè®®è§‚æœ›ï¼Œç­‰å¾…æ˜ç¡®çªç ´ä¿¡å·ã€‚"
        },
        "news_context": """- **è…¾è®¯è§†é¢‘å· 2024 å¹´ GMV è¶… 3000 äº¿ï¼Œå¹¿å‘Šæ”¶å…¥åŒæ¯”å¢é•¿ 45%**: è…¾è®¯å…¬å¸ƒæœ€æ–°è´¢æŠ¥å¿«æŠ¥ï¼Œè§†é¢‘å·æˆä¸ºå…¬å¸æ–°çš„å¢é•¿å¼•æ“ï¼Œæ—¥æ´»è·ƒç”¨æˆ·çªç ´ 5.2 äº¿ã€‚ç”µå•†ä¸šåŠ¡ GMV äº¦ç°çˆ†å‘å¼å¢é•¿ï¼Œåˆ†æå¸ˆé¢„è®¡æœªæ¥ä¸‰å¹´å°†ç»´æŒ 30% ä»¥ä¸Šå¢é€Ÿã€‚ (Source: https://finance.sina.com.cn/tech/2026-01-08/doc-imxz.shtml)
- **å›½è¡Œã€ŠVALORANTã€‹æ— ç•å¥‘çº¦æ‰‹æ¸¸ç‰ˆè·æ‰¹ç‰ˆå·**: å›½å®¶æ–°é—»å‡ºç‰ˆç½²å‘å¸ƒ 2026 å¹´ 1 æœˆè¿›å£ç½‘ç»œæ¸¸æˆå®¡æ‰¹ä¿¡æ¯ï¼Œè…¾è®¯é‡ç£…å¤§ä½œã€Šæ— ç•å¥‘çº¦ã€‹æ‰‹æ¸¸åœ¨åˆ—ã€‚å¸‚åœºæ™®éçœ‹å¥½å…¶æ¥æ£’ã€Šç‹è€…è£è€€ã€‹æˆä¸ºä¸‹ä¸€ä¸ªå›½æ°‘çº§æ‰‹æ¸¸ã€‚ (Source: https://gamelook.com.cn/2026/01/news-123.html)
- **å¤§è‚¡ä¸œ Prosus å®£å¸ƒå®Œæˆæœ¬è½®å‡æŒè®¡åˆ’**: è…¾è®¯ä¸»è¦è‚¡ä¸œ Prosus å‘å¸ƒå…¬å‘Šç§°ï¼Œå·²å®Œæˆè¿‡å» 6 ä¸ªæœˆçš„å‡æŒè®¡åˆ’ï¼Œå¹¶æ²¡æœ‰è¿›ä¸€æ­¥å‡æŒæ„å‘ã€‚æ­¤ä¸¾è¢«è§†ä¸ºæ¶ˆé™¤äº†å¸‚åœºçŸ­æœŸæœ€å¤§çš„æŠ›å‹æ¥æºã€‚ (Source: https://bloomberg.com/news/2026-01-07/prosus-tencent-stake.html)
- **å¾®ä¿¡æ”¯ä»˜æ¨å‡ºã€ŒæŒçº¹æ”¯ä»˜ 2.0ã€ï¼Œè¦†ç›–å…¨å›½åœ°é“**: å¾®ä¿¡æ”¯ä»˜å®£å¸ƒå‡çº§æŒçº¹æ”¯ä»˜æŠ€æœ¯ï¼Œè¯†åˆ«é€Ÿåº¦æå‡ 50%ï¼Œå¹¶å°†äºæœ¬æœˆèµ·åœ¨åŒ—äº¬ã€ä¸Šæµ·ã€æ·±åœ³åœ°é“å…¨é¢è¯•è¿è¡Œã€‚ (Source: https://tech.qq.com/a/20260108/001.htm)"""
    },
    {
        "symbol": "TSLA",
        "stock_name": "ç‰¹æ–¯æ‹‰",
        "tech_data": {
            "signal": "Bearish",
            "confidence": 0.82,
            "close": 215.50,
            "change_percent": -4.30,
            "support_price": 200.00,
            "pressure_price": 230.00,
            "rsi": 28.5,
            "kdj_k": 15,
            "kdj_d": 22,
            "macd": -2.41,
            "ai_reasoning": "è‚¡ä»·è·Œç ´å…³é”®æ”¯æ’‘ä½ 220 ç¾å…ƒï¼Œå½¢æˆå¤´éƒ¨å½¢æ€ã€‚RSI è¿›å…¥è¶…å–åŒºä½†æœªè§èƒŒç¦»ï¼ŒMACD æ­»å‰å‘ä¸‹å‘æ•£ã€‚ç©ºå¤´åŠ¨èƒ½å¼ºåŠ²ï¼Œå»ºè®®è§„é¿é£é™©æˆ–é€¢é«˜åšç©ºã€‚"
        },
        "news_context": """- **ç‰¹æ–¯æ‹‰ç¬¬å››å­£åº¦äº¤ä»˜é‡ 45 ä¸‡è¾†ï¼Œä¸åŠå¸‚åœºé¢„æœŸçš„ 48 ä¸‡è¾†**: ç‰¹æ–¯æ‹‰å…¬å¸ƒ Q4 äº¤ä»˜æ•°æ®ï¼Œå—é™äºä¸Šæµ·å·¥å‚äº§çº¿å‡çº§å’Œå¾·å›½å·¥å‚ç½¢å·¥å½±å“ï¼Œäº¤ä»˜é‡ç½•è§å‡ºç°ç¯æ¯”ä¸‹æ»‘ã€‚åˆ†æå¸ˆçº·çº·ä¸‹è°ƒç›®æ ‡ä»·ã€‚ (Source: https://cnbc.com/2026/01/08/tesla-q4-delivery-miss.html)
- **Cybertruck äº§èƒ½çˆ¬å¡é‡é˜»ï¼Œé©¬æ–¯å…‹æ‰¿è®¤ã€Œåœ°ç‹±æ¨¡å¼ã€**: åœ¨æœ€æ–°çš„å†…éƒ¨é‚®ä»¶ä¸­ï¼Œé©¬æ–¯å…‹æ‰¿è®¤ Cybertruck çš„ 4680 ç”µæ± è‰¯ç‡æœªè¾¾æ ‡ï¼Œå¤§è§„æ¨¡é‡äº§æ—¶é—´è¡¨æ¨è¿Ÿè‡³ 2026 ä¸‹åŠå¹´ã€‚ (Source: https://theverge.com/cars/2026/01/08/cybertruck-delay.html)
- **ç¾å›½å–æ¶ˆéƒ¨åˆ†ç”µåŠ¨è½¦ç¨æ”¶æŠµå…èµ„æ ¼**: æ‹œç™»æ”¿åºœæœ€æ–°çš„ã€Šé€šèƒ€å‰Šå‡æ³•æ¡ˆã€‹ç»†åˆ™ç”Ÿæ•ˆï¼ŒModel 3 åè½®é©±åŠ¨ç‰ˆå› ç”µæ± ç»„ä»¶æ¥æºé—®é¢˜ï¼Œå¤±å» 7500 ç¾å…ƒçš„å…¨é¢ç¨æ”¶æŠµå…èµ„æ ¼ã€‚ (Source: https://reuters.com/business/autos-transportation/ev-tax-credit-rules-2026.html)"""
    }
]

# =====================================================
# æ¨¡å‹é…ç½®
# =====================================================
MODEL_CONFIGS = {
    # Gemini Local (åŸºå‡†)
    "gemini-local": {
        "provider": "openai",
        "base_url": os.getenv("GEMINI_LOCAL_BASE_URL", "http://127.0.0.1:8045") + "/v1",
        "api_key": os.getenv("LLM_API_KEY", "sk-test"),
        "model": os.getenv("GEMINI_LOCAL_MODEL", "gemini-3-flash"),
        "description": "æœ¬åœ° Gemini ä»£ç† (åŸºå‡†)",
    },
    # æ··å…ƒæ¨¡å‹ç³»åˆ—
    "hunyuan-lite": {
        "provider": "openai",
        "base_url": "https://api.hunyuan.cloud.tencent.com/v1",
        "api_key": os.getenv("HUNYUAN_API_KEY"),
        "model": "hunyuan-lite",
        "description": "è…¾è®¯æ··å…ƒ Lite (å…è´¹)",
    },
    "hunyuan-standard": {
        "provider": "openai",
        "base_url": "https://api.hunyuan.cloud.tencent.com/v1",
        "api_key": os.getenv("HUNYUAN_API_KEY"),
        "model": "hunyuan-standard",
        "description": "è…¾è®¯æ··å…ƒ Standard",
    },
    "hunyuan-turbo": {
        "provider": "openai",
        "base_url": "https://api.hunyuan.cloud.tencent.com/v1",
        "api_key": os.getenv("HUNYUAN_API_KEY"),
        "model": "hunyuan-turbo",
        "description": "è…¾è®¯æ··å…ƒ Turbo (æ¨è)",
    },
    "hunyuan-pro": {
        "provider": "openai",
        "base_url": "https://api.hunyuan.cloud.tencent.com/v1",
        "api_key": os.getenv("HUNYUAN_API_KEY"),
        "model": "hunyuan-pro",
        "description": "è…¾è®¯æ··å…ƒ Pro (æœ€å¼º)",
    },
    "hunyuan-turbo-latest": {
        "provider": "openai",
        "base_url": "https://api.hunyuan.cloud.tencent.com/v1",
        "api_key": os.getenv("HUNYUAN_API_KEY"),
        "model": "hunyuan-turbo-latest",
        "description": "è…¾è®¯æ··å…ƒ Turbo Latest",
    },
}

# =====================================================
# ç”Ÿäº§ç¯å¢ƒ Prompt (å®Œå…¨å¤åˆ» brief_generator.py)
# =====================================================
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ StockWise çš„é¦–å¸­è´¢ç»ä¸»ç¬”ã€‚ä½ çš„ç›®æ ‡æ˜¯ç¼–å†™ä¸€ä»½**é€šä¿—æ˜“æ‡‚ã€èšç„¦å¸‚åœºå™äº‹**çš„ä¸ªè‚¡æ—¥æŠ¥ã€‚

æ ¸å¿ƒå†™ä½œåŸåˆ™ï¼š
1. **æ–°é—»é©±åŠ¨é€»è¾‘**ï¼šä¼˜å…ˆç®€è¿°"å‘ç”Ÿäº†ä»€ä¹ˆ"ï¼ˆæ–°é—»/è¡Œä¸šåŠ¨æ€ï¼‰ï¼Œä»¥æ­¤è§£é‡Šè‚¡ä»·è¡¨ç°ã€‚
2. **æ•°æ®éšå½¢åŒ–**ï¼š**ä¸¥ç¦**ç›´æ¥ç½—åˆ— RSIã€KDJã€MA ç­‰æŠ€æœ¯æŒ‡æ ‡æ•°å€¼ã€‚
   - âŒ é”™è¯¯ï¼šRSI ä¸º 75ï¼ŒMA5 ä¸Šç©¿ MA20ã€‚
   - âœ… æ­£ç¡®ï¼šçŸ­æœŸåŠ¨èƒ½å¼ºåŠ²ï¼Œè‚¡ä»·å‘ˆç°åŠ é€Ÿä¸Šè¡Œæ€åŠ¿ã€‚
3. **AI è§‚ç‚¹è‡ªç„¶èå…¥**ï¼šå°† AI çš„ä¿¡å·ï¼ˆBullish/Bearishï¼‰è½¬åŒ–ä¸ºå¯¹è¶‹åŠ¿çš„å®šæ€§æè¿°ï¼ˆå¦‚"ä¸Šæ¶¨è¶‹åŠ¿ç¨³å›º"ã€"çŸ­æœŸé¢ä¸´è°ƒæ•´å‹åŠ›"ï¼‰ï¼Œä¸è¦æåŠ"AI ä¿¡å·"è¿™ä¸ªè¯ã€‚
4. **è¯´äººè¯**ï¼šè®©æ²¡æœ‰é‡‘èèƒŒæ™¯çš„ç”¨æˆ·ä¹Ÿèƒ½ä¸€çœ¼çœ‹æ‡‚æ˜¯"å¥½"è¿˜æ˜¯"å"ã€‚"""

def build_user_prompt(case: Dict) -> str:
    # æ„é€  Hard Data Section
    td = case['tech_data']
    signal = td.get('signal', 'Side')
    confidence = td.get('confidence', 0)
    conf_pct = int(confidence * 100) if confidence <= 1 else int(confidence)
    
    hard_data_lines = [
        f"- AI ä¿¡å·: {signal} (ç½®ä¿¡åº¦ {conf_pct}%)",
    ]
    
    if td.get('close'):
        change = td.get('change_percent', 0)
        change_str = f"+{change:.2f}%" if change >= 0 else f"{change:.2f}%"
        hard_data_lines.append(f"- ä»Šæ—¥æ”¶ç›˜: {td['close']:.2f} ({change_str})")
        
    levels = []
    if td.get('support_price'): levels.append(f"æ”¯æ’‘ä½ {td['support_price']:.2f}")
    if td.get('pressure_price'): levels.append(f"å‹åŠ›ä½ {td['pressure_price']:.2f}")
    if levels: hard_data_lines.append(f"- å…³é”®ä»·ä½: {' | '.join(levels)}")
    
    indicators = []
    if td.get('rsi'): indicators.append(f"RSI={td['rsi']:.1f}")
    if td.get('kdj_k'): indicators.append(f"KDJ(K={td['kdj_k']}/D={td['kdj_d']})")
    if td.get('macd'): indicators.append(f"MACD={td['macd']:.3f}")
    if indicators: hard_data_lines.append(f"- æŠ€æœ¯æŒ‡æ ‡: {' | '.join(indicators)}")
    
    hard_data_section = "\n".join(hard_data_lines)
    
    return f"""Subject: {case['symbol']} ({case['stock_name']})

[ç¡¬æ•°æ®æ”¯æ’‘ - ä»…ä¾›ä½ å‚è€ƒï¼Œä½œä¸º"éšæ€§é€»è¾‘"ï¼Œä¸è¦ç›´æ¥å±•ç¤ºæ•°æ®]
{hard_data_section}

[åˆ†æå¸ˆæ¨ç† - ä¾›å‚è€ƒé€»è¾‘]
{td.get('ai_reasoning', '')}

[ä»Šæ—¥æ–°é—» - ä½œä¸ºå™äº‹æ ¸å¿ƒ]
{case['news_context']}

ä»»åŠ¡: æ’°å†™æ¯æ—¥ç®€æŠ¥ï¼ˆä¸è¦åŒ…å«ä»»ä½•æ ‡é¢˜ï¼‰ã€‚æ ¼å¼å¦‚ä¸‹ï¼š

1. **ç»¼åˆåˆ†æ** (çº¦60-80å­—)ï¼š
   - ä»¥ä»Šæ—¥æ ¸å¿ƒæ–°é—»æˆ–è¡Œä¸šåŠ¨æ€å¼€å¤´ã€‚
   - ç»“åˆè‚¡ä»·è¡¨ç°ï¼Œç”¨è‡ªç„¶çš„è¯­è¨€æè¿°å½“å‰è¶‹åŠ¿ï¼ˆåŸºäº AI ä¿¡å·å’ŒæŠ€æœ¯é¢ï¼‰ã€‚
   - **ç¦æ­¢**å‡ºç°å…·ä½“æŠ€æœ¯æŒ‡æ ‡åç§°å’Œæ•°å€¼ã€‚

2. **æ ¸å¿ƒæ–°é—» (é™„å‡ºå¤„)** (æœ€å¤š3æ¡ï¼Œæ ¼å¼ï¼š**[æ ‡é¢˜]**ï¼šæ‘˜è¦ã€‚[å‡ºå¤„é“¾æ¥](URL))
   - å¦‚æœæ²¡æœ‰é‡å¤§æ–°é—»ï¼Œæ­¤éƒ¨åˆ†æ˜¾ç¤º"ä»Šæ—¥æ— é‡å¤§å…¬å¼€æ–°é—»"ï¼Œé€šè¿‡æŠ€æœ¯é¢å½¢æ€ç•¥ä½œè¡¥å……ã€‚

è¾“å‡ºè¯­è¨€ï¼šä¸“ä¸šã€æµç•…ã€æœ‰æ¸©åº¦çš„ä¸­æ–‡ã€‚"""

# =====================================================
# LLM è°ƒç”¨
# =====================================================
def call_model(config: Dict, prompt: str) -> Tuple[str, float, Dict]:
    from openai import OpenAI
    
    if not config.get("api_key"):
        return "âŒ API Key æœªé…ç½®", 0, {"error": "Missing API Key"}
    
    client = OpenAI(
        api_key=config["api_key"],
        base_url=config["base_url"],
    )
    
    start_time = time.time()
    try:
        response = client.chat.completions.create(
            model=config["model"],
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            temperature=0.3,
            max_tokens=800,
        )
        elapsed = time.time() - start_time
        
        content = response.choices[0].message.content
        usage = response.usage
        
        meta = {
            "input_tokens": usage.prompt_tokens if usage else 0,
            "output_tokens": usage.completion_tokens if usage else 0,
            "total_tokens": usage.total_tokens if usage else 0,
        }
        
        return content, elapsed, meta
        
    except Exception as e:
        elapsed = time.time() - start_time
        return f"âŒ é”™è¯¯: {str(e)[:100]}", elapsed, {"error": str(e)}

# =====================================================
# ä¸»ç¨‹åº
# =====================================================
def run_benchmark(model_filter: str = None):
    # Auto-disable proxy for Hunyuan
    os.environ["NO_PROXY"] = "api.hunyuan.cloud.tencent.com"
    
    models_to_test = MODEL_CONFIGS.keys() if not model_filter else [model_filter]
    
    print("=" * 60)
    print("ğŸ“Š Brief Generation Benchmark (Advanced)")
    print("=" * 60)
    
    results = []
    
    for model_id in models_to_test:
        if model_id not in MODEL_CONFIGS:
            print(f"âŒ æœªçŸ¥æ¨¡å‹: {model_id}")
            continue
            
        config = MODEL_CONFIGS[model_id]
        print(f"\nğŸ¤– æµ‹è¯•æ¨¡å‹: {model_id} ({config['description']})")
        print("-" * 40)
        
        for case in TEST_CASES:
            prompt = build_user_prompt(case)
            
            print(f"   ğŸ“ˆ {case['symbol']} {case['stock_name']}...", end=" ", flush=True)
            
            content, elapsed, meta = call_model(config, prompt)
            
            if "error" in meta:
                print(f"âŒ ({elapsed:.1f}s)")
                print(f"      Error: {meta['error'][:50]}")
            else:
                print(f"âœ… ({elapsed:.1f}s, {meta['total_tokens']} tokens)")
                
            results.append({
                "model": model_id,
                "symbol": case['symbol'],
                "elapsed": elapsed,
                "tokens": meta.get("total_tokens", 0),
                "content": content,
                "success": "error" not in meta,
            })
            
            # æ˜¾ç¤ºç”Ÿæˆçš„ç®€æŠ¥é¢„è§ˆ (å‰200å­—)
            if "error" not in meta:
                preview = content.replace('\n', ' ')[:150]
                print(f"      ğŸ“ {preview}...")
    
    # æ±‡æ€»æŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ±‡æ€»æŠ¥å‘Š")
    print("=" * 60)
    
    for model_id in models_to_test:
        if model_id not in MODEL_CONFIGS:
            continue
        model_results = [r for r in results if r['model'] == model_id]
        success_count = sum(1 for r in model_results if r['success'])
        avg_time = sum(r['elapsed'] for r in model_results) / len(model_results) if model_results else 0
        
        status = "âœ…" if success_count == len(model_results) else "âš ï¸"
        print(f"{status} {model_id:25}: {success_count}/{len(model_results)} æˆåŠŸ | Avg: {avg_time:.1f}s")

def list_models():
    print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
    print("-" * 60)
    for model_id, config in MODEL_CONFIGS.items():
        key_status = "âœ…" if config.get("api_key") else "âŒ"
        print(f"  {key_status} {model_id:25} - {config['description']}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Brief Generation Benchmark Tool")
    parser.add_argument("--model", type=str, help="æŒ‡å®šæµ‹è¯•çš„æ¨¡å‹ID")
    parser.add_argument("--list", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹")
    
    args = parser.parse_args()
    
    if args.list:
        list_models()
    else:
        run_benchmark(args.model)
