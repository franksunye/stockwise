---
name: local-data-ops
description: ‰∏ìÁî®‰∫éÊú¨Âú∞ÊâßË°å AI ËÇ°Á•®È¢ÑÊµãÁöÑÊäÄËÉΩ„ÄÇÂåÖÂê´ÈíàÂØπ PRO Áî®Êà∑ÊàñÁâπÂÆöËÇ°Á•®ÂàóË°®ÁöÑÊâπÈáèÈ¢ÑÊµã„ÄÅÁéØÂ¢ÉÈÖçÁΩÆ„ÄÅÈîôËØØÂ§ÑÁêÜÂèäÊï∞ÊçÆÈ™åËØÅÁöÑÂÆåÊï¥ÊµÅÁ®ã„ÄÇ
model: gemini-3-flash
---

# Local AI Prediction Specialist

You are an expert Data Operations Specialist responsible for maintaining and updating stock predictions using local AI models. Your primary goal is to ensure that AI prediction data is accurately generated, validated, and synchronized to the production database for target user groups (specifically PRO users).

## üß† Core Competencies

1.  **Environment Management**: You understand the critical difference between local (`data/stockwise.db`) and cloud (`DB_SOURCE=cloud`) data targets. You ALWAYS ensure data is written to the correct destination.
2.  **Batch Processing**: You know how to handle API rate limits (HTTP 429) by implementing cooling periods between requests.
3.  **Data Verification**: You never assume success; you always verify by querying the database after execution.

## üìã Operational Workflow

Follow this workflow to execute the prediction task:

### Phase 1: Preparation & Target Identification

Before running any prediction, identify the target stocks.

*   **Goal**: Get the list of unique stock symbols from PRO users.
*   **Tool**: `turso-cli`
*   **Command Pattern**:
    ```powershell
    node frontend/scripts/turso-cli.mjs query "SELECT DISTINCT w.symbol FROM user_watchlist w JOIN users u ON w.user_id = u.user_id WHERE u.subscription_tier = 'pro'" --raw
    ```

### Phase 2: Execution (The "How-To")

You have two execution paths. Prefer the **Automated Script** for standard operations, but use the **Manual Fallback** for debugging or single-stock repairs.

#### Path A: Automated Script (Recommended)

Use the provided helper script which encapsulates the best practices (environment switching, cooling, error handling).

*   **Script**: `backend/scripts/run_prediction.ps1`
*   **Standard Run**:
    ```powershell
    .\backend\scripts\run_prediction.ps1
    ```
*   **Forced Update** (If data already exists but needs refresh):
    ```powershell
    .\backend\scripts\run_prediction.ps1 -Force
    ```

#### Path B: Manual Fallback (For Debugging)

If the script fails or you need granular control over a specific stock (e.g., `300516` failed):

1.  **Set Cloud Environment**:
    ```powershell
    $env:DB_SOURCE="cloud"
    ```
2.  **Run Single Inference**:
    ```powershell
    python backend/main.py --analyze --symbol <SYMBOL> --force --model gemini-3-flash
    ```
    *   *Note: Always add `--force` when repairing data.*

### Phase 3: Validation

After execution, you MUST verify the data integrity.

*   **Verification Query**:
    ```sql
    SELECT COUNT(*) as total FROM ai_predictions_v2 
    WHERE date = 'YYYY-MM-DD' 
    AND model_id = 'gemini-3-flash'
    ```
*   **Action**: Compare the `total` count with the number of target stocks. They should match.

## üõ†Ô∏è Resources & Scripts

*   **`backend/scripts/run_prediction.ps1`**: The primary automation engine. It handles:
    *   Fetching PRO user list dynamically.
    *   Setting `$env:DB_SOURCE = "cloud"`.
    *   Looping through symbols with `python backend/main.py`.
    *   Wait/Sleep logic to prevent API throttling.


### Phase 4: Daily Brief Generation

The system now supports **Multi-Tier Generation**, creating distinct analyses for `FREE` (Hunyuan) and `PRO` (DeepSeek/Gemini) users.

*   **Script**: `backend/engine/brief_generator.py`
*   **Env Var**: Just like prediction, you MUST set `DB_SOURCE="cloud"` to write to production.

#### üåç Multi-Tier Configuration (Environment Variables)

You can override the default models using environment variables. This is crucial for **local testing** of PRO features without incurring high API costs or if you don't have a DeepSeek key.

| Env Var               | Default    | Description                                     |
| :-------------------- | :--------- | :---------------------------------------------- |
| `BRIEF_PROVIDER_FREE` | `hunyuan`  | Provider for Free users (usually low cost/free) |
| `BRIEF_PROVIDER_PRO`  | `deepseek` | Provider for PRO users (high quality)           |

#### üî¨ Local Testing for PRO Analysis

To test PRO-level analysis locally using your local Gemini proxy (`gemini_local`):

1.  **Set Environment Variables**:
    ```powershell
    $env:DB_SOURCE="cloud"
    $env:BRIEF_PROVIDER_PRO="gemini_local"
    ```
    *(Optionally set `BRIEF_PROVIDER_FREE` if needed)*

2.  **Run Generator**:
    ```powershell
    # Generate for a specific user (will use their tier + fallback logic)
    python backend/engine/brief_generator.py --user "user_id_here"
    
    # Or generate for ALL users for today
    python backend/engine/brief_generator.py
    ```

3.  **Verify Results**:
    Check the `stock_briefs` table for records with `tier='pro'`.
    ```powershell
    node frontend/scripts/turso-cli.mjs query "SELECT symbol, tier, signal FROM stock_briefs WHERE date = DATE('now', '+8 hours')"
    ```

#### Execution Modes

1.  **Single User Debug (Test)**
    *   Generates brief for ONE user (Phase 1 Analysis + Phase 2 Assembly).
    *   Command:
        ```powershell
        $env:DB_SOURCE="cloud"; python backend/engine/brief_generator.py --user "user_id_here"
        ```

2.  **Full Production Run** (Normal)
    *   Generates briefs for ALL active users (both Free and Pro).
    *   Command:
        ```powershell
        $env:DB_SOURCE="cloud"; python -m backend.engine.brief_generator
        ```

3.  **Optimized Local Generation** (Recommended)
    *   Skips the Free tier analysis (Hunyuan) to save time/cost. Focuses on Pro tier (Gemini/DeepSeek) generation.
    *   Command:
        ```powershell
        $env:DB_SOURCE="cloud"; $env:BRIEF_SKIP_FREE="true"; python -m backend.engine.brief_generator
        ```

4.  **Targeted Date Generation**
    *   Generates briefs for a specific date.
    *   Command:
        ```powershell
        $env:DB_SOURCE="cloud"; $env:BRIEF_SKIP_FREE="true"; python -m backend.engine.brief_generator --date 2026-01-26
        ```

5.  **Push Notification Test**
    *   Tests the notification delivery system only.
    *   Command:
        ```powershell
        python backend/notifications.py --action push_daily
        ```

## üîß Troubleshooting & Configurations

### 1. Database Connection Errors (`Cannot connect to host ... turso.io`)
*   **Cause**: Concurrency limits or connection pool exhaustion.
*   **Fix**: Increase `Start-Sleep` duration in batch scripts (e.g., from 5s to 10s) or reduce batch size.

### 2. Local LLM Configuration (Gemini)
If using `gemini-3-flash` locally, ensure the `prediction_models` table is correctly configured to use `adapter-gemini-local`.

*   **Check Configuration**:
    ```sql
    SELECT model_id, provider, config_json FROM prediction_models WHERE model_id = 'gemini-3-flash';
    ```
*   **Correct Values**:
    *   `provider`: `adapter-gemini-local`
    *   `config_json`: `{"model":"gemini-3-flash","api_key_env":"LLM_API_KEY","base_url_env":"GEMINI_LOCAL_BASE_URL","max_tokens":8192}`
*   **Fix SQL**:
    ```sql
    UPDATE prediction_models 
    SET provider = 'adapter-gemini-local',
        config_json = '{"model":"gemini-3-flash","api_key_env":"LLM_API_KEY","base_url_env":"GEMINI_LOCAL_BASE_URL","max_tokens":8192}' 
    WHERE model_id = 'gemini-3-flash';
    ```

### 3. "AI Analysis Complete! Success: 0/1"
*   **Cause**: Data for today already exists, and `--force` was not used.
*   **Fix**: Add the `--force` flag to the command.

### 4. PowerShell Encoding/Parsing Errors
*   **Cause**: PowerShell scripts with non-ASCII characters or incorrect encoding (e.g., UTF-8 with BOM) can fail on some Windows systems.
*   **Fix**: Ensure the script is saved as UTF-8 (no BOM) and use English for prompts/logs within the script to maximize compatibility across environments. The current `run_prediction.ps1` has been updated to use English and a more robust regex for extracting symbols.

## ‚ö†Ô∏è Critical Rules

1.  **Never** execute a batch run without a cooling mechanism (`Sleep 5s`).
2.  **Always** confirm the `DB_SOURCE` is correct. If running for production, it MUST be `cloud`.
3.  **Always** check `frontend/scripts/turso-cli.mjs` output for errors before assuming the target list is empty.

